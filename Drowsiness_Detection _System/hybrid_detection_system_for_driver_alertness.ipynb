{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a78a486-f8ad-41ec-b425-45e777a6a66c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "379ca9a6-f209-4741-9a1d-0bd15745b878",
   "metadata": {},
   "source": [
    "Hybrid Detection System for Driver Alertness:\n",
    "\n",
    "Combine Eye Tracking, Yawning, and Head Pose Detection: Integrate\n",
    "multiple indicators to detect drowsiness more accurately. Use a combination of eye\n",
    "state (open/closed), head movement, and yawning frequency to trigger drowsiness\n",
    "alerts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ece5bbc-31cd-432d-91cd-3cc9fc62170e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'19.24.6'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dlib\n",
    "dlib.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0a0ea7a-6bf2-4430-b67e-78926176f0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the necessary libraries\n",
    "import numpy as np\n",
    "import dlib\n",
    "import cv2\n",
    "from math import hypot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "112d15ff-0aef-4607-a209-7dabaa5bd99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the video capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Correct function to get the face detector\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "# Ensure correct shape predictor file path\n",
    "predictor = dlib.shape_predictor(\"/Users/ashutoshtomar/Desktop/Project/driver-drowsiness-project/shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "\n",
    "# Function to find the midpoint between two points\n",
    "def mid(p1, p2):\n",
    "    return int((p1.x + p2.x) / 2), int((p1.y + p2.y) / 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83a91467-ddde-4c0a-88df-8a36ae5ca40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eye aspect ratio calculation\n",
    "def eye_aspect_ratio(eye_landmark, face_roi_landmark):\n",
    "    left_point = (face_roi_landmark.part(eye_landmark[0]).x, face_roi_landmark.part(eye_landmark[0]).y)\n",
    "    right_point = (face_roi_landmark.part(eye_landmark[3]).x, face_roi_landmark.part(eye_landmark[3]).y)\n",
    "    center_top = mid(face_roi_landmark.part(eye_landmark[1]), face_roi_landmark.part(eye_landmark[2]))\n",
    "    center_bottom = mid(face_roi_landmark.part(eye_landmark[5]), face_roi_landmark.part(eye_landmark[4]))\n",
    "\n",
    "    hor_line_length = hypot((left_point[0] - right_point[0]), (left_point[1] - right_point[1]))\n",
    "    ver_line_length = hypot((center_top[0] - center_bottom[0]), (center_top[1] - center_bottom[1]))\n",
    "\n",
    "    ratio = hor_line_length / ver_line_length\n",
    "    return ratio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a26f84ec-2a78-4253-acf6-a2c9d7a38dd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-20 23:41:30.153 python[37937:2910633] +[IMKClient subclass]: chose IMKClient_Modern\n",
      "2024-12-20 23:41:30.153 python[37937:2910633] +[IMKInputSession subclass]: chose IMKInputSession_Modern\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Mouth aspect ratio calculation\n",
    "def mouth_aspect_ratio(lips_landmark, face_roi_landmark):\n",
    "    left_point = (face_roi_landmark.part(lips_landmark[0]).x, face_roi_landmark.part(lips_landmark[0]).y)\n",
    "    right_point = (face_roi_landmark.part(lips_landmark[2]).x, face_roi_landmark.part(lips_landmark[2]).y)\n",
    "    center_top = (face_roi_landmark.part(lips_landmark[1]).x, face_roi_landmark.part(lips_landmark[1]).y)\n",
    "    center_bottom = (face_roi_landmark.part(lips_landmark[3]).x, face_roi_landmark.part(lips_landmark[3]).y)\n",
    "\n",
    "    hor_line_length = hypot((left_point[0] - right_point[0]), (left_point[1] - right_point[1]))\n",
    "    ver_line_length = hypot((center_top[0] - center_bottom[0]), (center_top[1] - center_bottom[1]))\n",
    "    if hor_line_length == 0:\n",
    "        return ver_line_length\n",
    "    ratio = ver_line_length / hor_line_length\n",
    "    return ratio\n",
    "\n",
    "\n",
    "count = 0\n",
    "font = cv2.FONT_HERSHEY_TRIPLEX\n",
    "\n",
    "while True:\n",
    "    _, img = cap.read()\n",
    "    img = cv2.flip(img, 1)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = detector(gray)\n",
    "    for face_roi in faces:\n",
    "        landmark_list = predictor(gray, face_roi)\n",
    "\n",
    "        # Eye aspect ratio\n",
    "        left_eye_ratio = eye_aspect_ratio([36, 37, 38, 39, 40, 41], landmark_list)\n",
    "        right_eye_ratio = eye_aspect_ratio([42, 43, 44, 45, 46, 47], landmark_list)\n",
    "        eye_open_ratio = (left_eye_ratio + right_eye_ratio) / 2\n",
    "        cv2.putText(img, str(eye_open_ratio), (0, 13), font, 0.5, (100, 100, 100))\n",
    "\n",
    "        # Mouth aspect ratio\n",
    "        inner_lip_ratio = mouth_aspect_ratio([60, 62, 64, 66], landmark_list)\n",
    "        outer_lip_ratio = mouth_aspect_ratio([48, 51, 54, 57], landmark_list)\n",
    "        mouth_open_ratio = (inner_lip_ratio + outer_lip_ratio) / 2\n",
    "        cv2.putText(img, str(mouth_open_ratio), (448, 13), font, 0.5, (100, 100, 100))\n",
    "\n",
    "        # Detect drowsiness\n",
    "        if mouth_open_ratio > 0.380 and eye_open_ratio > 4.0 or eye_open_ratio > 4.30:\n",
    "            count += 1\n",
    "        else:\n",
    "            count = 0\n",
    "\n",
    "        # Draw rectangle and display sleepiness status\n",
    "        x, y = face_roi.left(), face_roi.top()\n",
    "        x1, y1 = face_roi.right(), face_roi.bottom()\n",
    "        if count > 10:\n",
    "            cv2.rectangle(img, (x, y), (x1, y1), (0, 0, 255), 2)\n",
    "            cv2.putText(img, \"Sleepy\", (x, y - 5), font, 0.5, (0, 0, 255))\n",
    "        else:\n",
    "            cv2.rectangle(img, (x, y), (x1, y1), (0, 255, 0), 2)\n",
    "\n",
    "    # Show the video feed\n",
    "    cv2.imshow(\"img\", img)\n",
    "\n",
    "    # Exit the loop on pressing the Escape key (27)\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e561c5b-0a04-46fe-86d5-81b6c173472f",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = cv2.waitKey(1)\n",
    "if key == 27:  # Check if 'Esc' key (ASCII code 27) is pressed\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee67c6d-fb8e-4013-a80a-10f64b020e71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
