{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0794490-74a6-4e34-99dc-85fd6f7b5792",
   "metadata": {},
   "source": [
    "# Driver Drowsiness Detecting System\n",
    "This model detects prolonged eye closure and frequent yawning, which can be signs of driver fatigue. \n",
    "To prevent incidents caused by drowsiness, our system alerts the driver in advance by analyzing drowsiness indicators.\n",
    "I am using Python as my programming language and leveraging libraries such as Pandas, NumPy, Dlib, OpenCV, and Math to build and train a driver drowsiness detection model.\n",
    "\n",
    "Currently, I am working with pretrained data for model training while also developing a custom dataset, which I train using TensorFlow/keras, PyTorch with a Cnn model. To enhance features extraction in dim light conditions since most accidents occur at night, \n",
    "I am integrating histogram techniques for improved accuracy in detecting drowsiness indicators.\n",
    "Additionally, I am working on head movement detection to ensure alertness even when the automobile is in motion and the system fails to detect a face. This feature helps provide timely alerts in situations where traditional face detection methods might not be reliable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4e421090-12d4-4453-bdc7-74777f131af5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'19.24.6'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dlib\n",
    "dlib.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "da6e4aa7-ccc4-44f2-8be0-fc78a1848a50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.10.0'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "cv2.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ad2e70b0-1132-4ffa-84e6-80c54574a57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import hypot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7314c2d2-bf8a-43f7-8020-a167ea862fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize video capture (Opencv) and dlib's face detector and shape predictor\n",
    "cap = cv2.VideoCapture(0)\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "# loding a pre trained facial landmark predictor model to detect 68 key point on the face\n",
    "predictor = dlib.shape_predictor(\"/Users/ashutoshtomar/Desktop/GitHub/heavy_project/Drowsiness_Detection _System/shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "\n",
    "# After detecting features, creating a function to calculate midpoint between two points\n",
    "def mid(p1, p2):\n",
    "    return int((p1.x + p2.x) / 2), int((p1.y + p2.y) / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d5c5b541-93e5-470e-9292-0730d256e840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate eye aspect ratio (EAR)\n",
    "def eye_aspect_ratio(eye_landmark, face_landmark):\n",
    "    left_point = (face_landmark.part(eye_landmark[0]).x, face_landmark.part(eye_landmark[0]).y)\n",
    "    right_point = (face_landmark.part(eye_landmark[3]).x, face_landmark.part(eye_landmark[3]).y)\n",
    "    center_top = mid(face_landmark.part(eye_landmark[1]), face_landmark.part(eye_landmark[2]))\n",
    "    center_bottom = mid(face_landmark.part(eye_landmark[5]), face_landmark.part(eye_landmark[4]))\n",
    "\n",
    "    hor_line_length = hypot((left_point[0] - right_point[0]), (left_point[1] - right_point[1]))\n",
    "    ver_line_length = hypot((center_top[0] - center_bottom[0]), (center_top[1] - center_bottom[1]))\n",
    "\n",
    "    ratio = hor_line_length / ver_line_length\n",
    "    return ratio\n",
    "\n",
    "# Function to calculate mouth aspect ratio (MAR)\n",
    "\n",
    "def mouth_aspect_ratio(lips_landmark, face_landmark):\n",
    "    left_point = (face_landmark.part(lips_landmark[0]).x, face_landmark.part(lips_landmark[0]).y)\n",
    "    right_point = (face_landmark.part(lips_landmark[2]).x, face_landmark.part(lips_landmark[2]).y)\n",
    "    center_top = (face_landmark.part(lips_landmark[1]).x, face_landmark.part(lips_landmark[1]).y)\n",
    "    center_bottom = (face_landmark.part(lips_landmark[3]).x, face_landmark.part(lips_landmark[3]).y)\n",
    "\n",
    "    hor_line_length = hypot((left_point[0] - right_point[0]), (left_point[1] - right_point[1]))\n",
    "    ver_line_length = hypot((center_top[0] - center_bottom[0]), (center_top[1] - center_bottom[1]))\n",
    "    if hor_line_length == 0:\n",
    "        return ver_line_length\n",
    "    ratio = ver_line_length / hor_line_length\n",
    "    return ratio\n",
    "\n",
    "# Function to calculate and display histogram for a given ROI\n",
    "def display_histogram(roi, title):\n",
    "    roi_gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "    hist = cv2.calcHist([roi_gray], [0], None, [256], [0, 256])\n",
    "    hist_normalized = cv2.normalize(hist, hist, 0, 255, cv2.NORM_MINMAX)\n",
    "    hist_image = np.zeros((100, 256), dtype=np.uint8)\n",
    "    for i in range(256):\n",
    "        cv2.line(hist_image, (i, 100), (i, 100 - int(hist_normalized[i])), 255, 1)\n",
    "    cv2.imshow(title, hist_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ee4bae15-f3bf-48c5-8934-48f68d146ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7n/sg8y0p8x2jxg2_zcq4f5b4br0000gn/T/ipykernel_3445/472534542.py:36: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  cv2.line(hist_image, (i, 100), (i, 100 - int(hist_normalized[i])), 255, 1)\n"
     ]
    }
   ],
   "source": [
    "# main loop\n",
    "count = 0\n",
    "font = cv2.FONT_HERSHEY_TRIPLEX\n",
    "while True:\n",
    "    _, img = cap.read()\n",
    "    img = cv2.flip(img, 1)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = detector(gray)\n",
    "    for face in faces:\n",
    "        landmark_list = predictor(gray, face)\n",
    "\n",
    "        # (EAR)- eye aspect ratio\n",
    "        left_eye_ratio = eye_aspect_ratio([36, 37, 38, 39, 40, 41], landmark_list)\n",
    "        right_eye_ratio = eye_aspect_ratio([42, 43, 44, 45, 46, 47], landmark_list)\n",
    "        eye_open_ratio = (left_eye_ratio + right_eye_ratio) / 2\n",
    "        cv2.putText(img, f\"EAR: {eye_open_ratio:.2f}\", (10, 20), font, 0.5, (100, 100, 100))\n",
    "\n",
    "        # (MAR) - mouth aspect ratio \n",
    "        inner_lip_ratio = mouth_aspect_ratio([60, 62, 64, 66], landmark_list)\n",
    "        outter_lip_ratio = mouth_aspect_ratio([48, 51, 54, 57], landmark_list)\n",
    "        mouth_open_ratio = (inner_lip_ratio + outter_lip_ratio) / 2\n",
    "        cv2.putText(img, f\"MAR: {mouth_open_ratio:.2f}\", (10, 40), font, 0.5, (100, 100, 100))\n",
    "\n",
    "        # Drowsiness detection logic\n",
    "        # If driver is yawming with open eyes it can still detecte it.\n",
    "        if mouth_open_ratio > 0.30 or eye_open_ratio > 3.90 or eye_open_ratio > 4.0:    # by manualy analysing \n",
    "            count += 1\n",
    "        else:\n",
    "            count = 0\n",
    "\n",
    "        # Draw rectangle around the face\n",
    "        x, y = face.left(), face.top()\n",
    "        x1, y1 = face.right(), face.bottom()\n",
    "        if count > 10:\n",
    "            cv2.rectangle(img, (x, y), (x1, y1), (0, 0, 255), 2)\n",
    "            cv2.putText(img, \"Drowsy\", (x, y - 5), font, 0.5, (0, 0, 255))\n",
    "        else:\n",
    "            cv2.rectangle(img, (x, y), (x1, y1), (0, 255, 0), 2)\n",
    "\n",
    "        # Extract eye and mouth regions for histogram analysis\n",
    "        left_eye_roi = img[landmark_list.part(37).y:landmark_list.part(41).y,landmark_list.part(36).x:landmark_list.part(39).x]\n",
    "        mouth_roi = img[landmark_list.part(51).y:landmark_list.part(57).y,landmark_list.part(48).x:landmark_list.part(54).x]\n",
    "\n",
    "        # Display for eye and mouth regions\n",
    "        if left_eye_roi.size != 0:\n",
    "            display_histogram(left_eye_roi, \"Left Eye\")\n",
    "        if mouth_roi.size != 0:\n",
    "            display_histogram(mouth_roi, \"Mouth\")\n",
    "\n",
    "    # display the output frame for testing\n",
    "    cv2.imshow(\"Driver Drowsiness Detection System\", img)\n",
    "\n",
    "    # Exit on 'esc' key press stop the processing model\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 27:\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "817f555e-aa1b-4356-83a9-973b4555d3a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'break' outside loop (193630545.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[60], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    break\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'break' outside loop\n"
     ]
    }
   ],
   "source": [
    "# for closing detection window\n",
    "key = cv2.waitKey(1)\n",
    "if key == 27:  \n",
    "    break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4fd3c5-c3fe-4121-aaa8-110caaca53b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
